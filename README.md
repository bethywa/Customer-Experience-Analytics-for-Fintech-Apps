âœ… Task 1 â€” Data Collection & Preprocessing
1. Scraping Google Play Reviews

Using google-play-scraper, the project extracts 500+ reviews per bank.

Script:

src/scraper.py


Output files:

data/raw/reviews_raw.csv â€” combined raw reviews

data/raw/app_info.csv â€” app metadata (title, ratings, installs, etc.)

2. Preprocessing Steps

Script:

src/preprocessing.py


Operations performed:

Remove duplicate reviews

Remove Amharic/Ethiopic script (keep only English text)

Drop rows missing essential fields (review_text, rating, bank_name)

Normalize dates â†’ YYYY-MM-DD

Clean whitespace and text noise

Compute text length

Validate rating values

Output:

data/processed/reviews_processed.csv (clean dataset for analysis)

3. Exploratory Data Analysis (EDA)

Notebook:

notebooks/preprocessing_eda.ipynb


Visualizations include:

Rating distribution

Number of reviews per bank

Review text-length distribution

âœ… Task 2 â€” Sentiment & Thematic Analysis
1. Sentiment Analysis (VADER)

Using VADER:

Calculates sentiment_score (âˆ’1 â†’ +1)

Assigns sentiment_label: positive, neutral, negative

Output:

data/sentiment/sentiment_results.csv

Notebook:

notebooks/sentiment_analysis.ipynb


Visualizations:

Sentiment distribution per bank (violin/box plots)

Positive/Negative proportions

2. Theme Extraction

Approach uses:

âœ” TF-IDF keyword extraction per bank
âœ” LDA topic modeling (4 topics)
âœ” Wordclouds per bank
âœ” Manual grouping of keywords into themes

Output files:

data/themes/tfidf_keywords.csv

data/themes/lda_topics.csv

data/themes/themes_by_bank.csv

Notebook:

notebooks/theme_extraction.ipynb


Themes identified include examples like:

UX & Interface Issues

Transaction & Payment Problems

Performance & Reliability

Customer Support

Account Access Issues

ğŸ“ Project Structure
Customer-Experience-Analytics-for-Fintech-Apps/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ sentiment.py (optional)
â”‚   â””â”€â”€ theme_extraction.py (optional)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ reviews_raw.csv
â”‚   â”‚   â””â”€â”€ app_info.csv
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â””â”€â”€ reviews_processed.csv
â”‚   â”œâ”€â”€ sentiment/
â”‚   â”‚   â””â”€â”€ sentiment_results.csv
â”‚   â””â”€â”€ themes/
â”‚       â”œâ”€â”€ tfidf_keywords.csv
â”‚       â”œâ”€â”€ lda_topics.csv
â”‚       â””â”€â”€ themes_by_bank.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing_eda.ipynb
â”‚   â”œâ”€â”€ sentiment_analysis.ipynb
â”‚   â””â”€â”€ theme_extraction.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                  (NOT uploaded / in .gitignore)
â””â”€â”€ README.md

ğŸš€ How to Run
1. Install dependencies
pip install -r requirements.txt

2. Add .env file (example)
CBE_APP_ID=com.combanketh.mobilebanking
BOA_APP_ID=com.boa.boaMobileBanking
DASHEN_APP_ID=com.dashen.dashensuperapp
REVIEWS_PER_BANK=500
MAX_RETRIES=3

3. Scrape reviews
python src/scraper.py

4. Preprocess reviews
python src/preprocessing.py

5. Run notebooks

Start Jupyter:

jupyter notebook


Then open the notebooks under notebooks/.

â­ Key Achievements

âœ” Successfully collected >1500 authentic Google Play reviews
âœ” Clean and structured dataset prepared for NLP analysis
âœ” Sentiment scoring using VADER
âœ” Theme extraction using TF-IDF + LDA topic modeling
âœ” Professional EDA and NLP visualizations


   ğŸ§© Task 3 â€” PostgreSQL Database Integration

This task focuses on storing the cleaned and processed app review data into a PostgreSQL relational database, simulating real-world data engineering workflows.

ğŸ“Œ Objectives

Install and configure PostgreSQL locally

Create a relational schema for banks and reviews

Insert processed dataset (1,463 reviews) into the database

Run basic SQL queries to validate data

Connect to PostgreSQL using SQLAlchemy

Explore the stored data in a Jupyter Notebook

ğŸ“‚ Folder Structure
Customer-Experience-Analytics-for-Fintech-Apps/
â”œâ”€ src/
â”‚  â”œâ”€ config.py                # Loads DB credentials
â”‚  â”œâ”€ db.py                    # SQLAlchemy engine
â”‚  â”œâ”€ schema.sql               # CREATE TABLES script
â”‚  â”œâ”€ insert_reviews.py        # Load CSV â†’ PostgreSQL
â”‚  â””â”€ verify_queries.py        # Test queries
â”œâ”€ notebooks/
â”‚  â””â”€ db_setup.ipynb     # DB exploration + plots
â”œâ”€ data/
â”‚  â””â”€ sentiment/sentiment_results.csv
â”œâ”€ .env

ğŸ›  Steps Performed
1ï¸âƒ£ Install PostgreSQL

Installed PostgreSQL 18 and set up:

Default superuser: postgres

New application user: review_user

Database: bank_reviews

Added PostgreSQL /bin folder to PATH so psql works in terminal.

2ï¸âƒ£ Create Database Schema

Executed the schema using:

psql -U postgres -d bank_reviews -f src/schema.sql


Created two tables:

banks

reviews

3ï¸âƒ£ Insert Cleaned Data

Inserted 1,463 cleaned and sentiment-scored reviews:

python src/insert_reviews.py


Automatically:

 - Inserted unique banks

  - Linked reviews â†’ banks via foreign key

   - Stored sentiment labels & sentiment scores

4ï¸âƒ£ Run Verification Queries

     . python src/verify_queries.py



5ï¸âƒ£ Explore in Notebook

Notebook: notebooks/db_setup.ipynb

Includes:
âœ” Connect to DB
âœ” Load reviews into pandas
âœ” Visualize sentiment distribution
âœ” Ratings distribution
âœ” Reviews per bank
âœ” Reviews over time
âœ” Top negative reviews

ğŸ“Š Key Results

  - 3 banks loaded

  - 1,463 reviews stored

  - Fully working PostgreSQL connection

  - Sentiment and rating data accurately preserved

  - Verified analytics using SQL and Notebook visualizations